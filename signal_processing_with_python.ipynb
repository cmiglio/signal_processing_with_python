{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal analysis with python\n",
    "\n",
    "*Carolina Migliorelli*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this workshop is to show an example on how to work with Python with signals. \n",
    "We will give some general ideas on how to **read, process and visualize data**\n",
    "\n",
    "We will use some common python toolboxes: \n",
    "* [numpy](https://numpy.org/): It contains the main functions to work with matrices (very similar to Matlab)\n",
    "* [pandas](https://pandas.pydata.org/): A way of organizing the data\n",
    "* [seaborn](https://seaborn.pydata.org/): A visualization library with nice plots (that use in its backgroud [matplotlib](https://matplotlib.org/).\n",
    "* [scipy](https://www.scipy.org/): We will use scipy to load mat files.\n",
    "* [mne](https://mne.tools/stable/index.html): A package for analyzing human neurophysiological data\n",
    "\n",
    "For this workshop, we will load data from one epileptic patient and we will extract some events of interest. We will plot the time-frequency representation of these events using the stockwell transform and we will save into a dataframe structure (a table) some meaningful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installing packages\n",
    "If you don't have installed the toolboxes, then you should install them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.18.1)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: seaborn in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: mne in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas seaborn scipy mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages \n",
    "We will start importing the packages. When we use *import* we import the whole package, with the name that we put after *as*. If we don't want to import the whole package but only some functions, we can use *from*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import mne\n",
    "from mne.time_frequency import (tfr_array_stockwell) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data\n",
    "### 2.1. Loading the data using loadmat (from scipy)\n",
    "We will load the data that, in this case, is stored in a *.mat* file. We can import data with other formats using MNE ([see here](https://mne.tools/stable/auto_tutorials/io/plot_20_reading_eeg_data.html#sphx-glr-auto-tutorials-io-plot-20-reading-eeg-data-py)). But however, .TRC (micromed) files are not currently included in MNE distribution, so what I did is reading the data with matlab and then save it into a .mat file. If you are interested in knowing how to create the .mat file, I cand send you my routines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files were saved into a structure, you should know the names of each field\n",
    "# in the structure. If not, you can check de names usign structure.keys().\n",
    "# The squeeze_me parameter must be set to True.\n",
    "structure = loadmat('signals.mat',squeeze_me=True)\n",
    "data = structure['data']\n",
    "sfreq = structure['sfreq']\n",
    "ch_names = structure['ch_names']\n",
    "ch_types = structure['ch_types']\n",
    "differential = structure['differential']\n",
    "average = structure['average']\n",
    "needle_names = structure['needle_names']\n",
    "needle = structure['needle1']\n",
    "pos = structure['pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Creating an mne raw array\n",
    "To work with MNE (and use filters for example), we have to create a data structure that MNE understands.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=20, n_times=61440\n",
      "    Range : 0 ... 61439 =      0.000 ...    59.999 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# We have to change the numpy arrays to lists\n",
    "info = mne.create_info(ch_names=ch_names.tolist(), sfreq=sfreq, ch_types=ch_types.tolist())\n",
    "raw = mne.io.RawArray(data, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing data\n",
    "### 3.1. Filtering with MNE\n",
    "We will filter the data above 80 Hz and we will notch the data to remove the line noise (50Hz and the harmonics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 20 x 61440 (60.0 sec), ~9.4 MB, data loaded>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.notch_filter([50, 100, 150, 200, 250], fir_design='firwin',verbose=False)\n",
    "raw80 = raw.copy() # We create a copy of our data\n",
    "raw80.filter(80,None,fir_design='firwin',verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Obtaining the envelope of the signal and computing the threshold\n",
    "We want to obtain the envelope of the signal using hilbert and to obtain the events that are higher than a threshold. We will set the threshold to:\n",
    "``` python\n",
    "mean + 3*sd.\n",
    "```\n",
    "(Other more sophisticated methods to obtain the threshold could be applyied)\n",
    "\n",
    "\n",
    "We will compute this only for one channel, but I leave you the code to compute this for all the channels (using for in python is easy, but a little bit different than in Matlab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to iterate trough channels is: \n",
    "\n",
    "```python\n",
    "\n",
    "# We obtain a vector that have the size of the channels and other vector with \n",
    "# the same size for the threshold\n",
    "channels_vector = np.arange(0,len(raw80.ch_names)) \n",
    "th = np.zeros(channels_vector.shape) \n",
    "\n",
    "for chan_n in channels_vector: # We iterate trough the channels\n",
    "    data_80 = raw80.get_data(picks=chan_n) # We obtain the data for one channel\n",
    "    data_hil = np.abs(raw_hilb.get_data(picks=chan_n)) # We obtain the envelope for one channel\n",
    "    th[chan_n] = np.mean(data_hil) + 3*np.std(data_hil)\n",
    "    \n",
    "    # All this code is to detect events of interest that will be saved into eoi\n",
    "    # Where function is similar to find\n",
    "    change = np.diff((data_hil[0,:]>th[chan_n])*1)\n",
    "    if change[np.where(change)[0][0]]==-1:\n",
    "        change[np.where(change)[0][0]]=0\n",
    "    ch_pos=np.sum(change==1)\n",
    "    ch_neg=np.sum(change==-1)\n",
    "    if ch_pos>ch_neg:\n",
    "        # Si hay 1 positivo mas que negativo, entonces es que hemos acabado encima del threshold--> descartamos el ultimo positivo\n",
    "        p_aux_ini=np.where(change==1)[0][:-2]\n",
    "        p_aux_fin=np.where(change==-1)[0]\n",
    "    elif ch_pos<ch_neg:\n",
    "        # Si hay 1 negativo más que un positivo, entonces es que he empezado encima del threshold--> descartamos el primer negativo\n",
    "        p_aux_ini=np.where(change==1)[0]\n",
    "        p_aux_fin=np.where(change==-1)[0][1:]\n",
    "    elif ch_pos==ch_neg:\n",
    "        p_aux_ini=np.where(change==1)[0]\n",
    "        p_aux_fin=np.where(change==-1)[0]\n",
    "    eoi = np.array(list(zip(p_aux_ini,p_aux_fin)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hilb = raw80.copy() # We create a copy of our filtered data\n",
    "raw_hilb.apply_hilbert() # We apply hilbert to obtain the envelope\n",
    "\n",
    "chan_n = 0 # We will compute this for the first channel (in python the first index is 0)\n",
    "\n",
    "data_80 = raw80.get_data(picks=chan_n)\n",
    "data_hil = np.abs(raw_hilb.get_data(picks=chan_n))\n",
    "th = np.mean(data_hil) + 3*np.std(data_hil)\n",
    "change = np.diff((data_hil[0,:]>th)*1)\n",
    "if change[np.where(change)[0][0]]==-1:\n",
    "    change[np.where(change)[0][0]]=0\n",
    "ch_pos=np.sum(change==1)\n",
    "ch_neg=np.sum(change==-1)\n",
    "if ch_pos>ch_neg:\n",
    "            # Si hay 1 positivo mas que negativo, entonces es que hemos acabado encima del threshold--> descartamos el ultimo positivo\n",
    "    p_aux_ini=np.where(change==1)[0][:-2]\n",
    "    p_aux_fin=np.where(change==-1)[0]\n",
    "elif ch_pos<ch_neg:\n",
    "     # Si hay 1 negativo más que un positivo, entonces es que he empezado encima del threshold--> descartamos el primer negativo\n",
    "    p_aux_ini=np.where(change==1)[0]\n",
    "    p_aux_fin=np.where(change==-1)[0][1:]\n",
    "elif ch_pos==ch_neg:\n",
    "    p_aux_ini=np.where(change==1)[0]\n",
    "    p_aux_fin=np.where(change==-1)[0]\n",
    "eoi = np.array(list(zip(p_aux_ini,p_aux_fin)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what we have in *eoi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23813 23867]\n",
      " [23872 23887]\n",
      " [23888 23893]\n",
      " [23895 23899]\n",
      " [23917 23942]\n",
      " [23943 23987]\n",
      " [24051 24101]\n",
      " [31403 31404]\n",
      " [31405 31409]\n",
      " [31410 31427]\n",
      " [31475 31500]\n",
      " [49991 49995]\n",
      " [49998 49999]\n",
      " [50000 50031]\n",
      " [50033 50037]\n",
      " [50092 50096]\n",
      " [50099 50105]\n",
      " [50106 50128]\n",
      " [50129 50130]\n",
      " [50136 50138]]\n"
     ]
    }
   ],
   "source": [
    "print(eoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
